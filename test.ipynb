{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2fffe3ce-3a9d-47f9-970a-c5de6a57f3ce.pdf\n",
      "1 files to process in current batch\n"
     ]
    }
   ],
   "source": [
    "# from grobid_client.grobid_client import GrobidClient\n",
    "\n",
    "# client = GrobidClient(config_path=\"./config.json\", check_server=False)\n",
    "# client.process(\"processFulltextDocument\", \"./test_pdf\", output=\"./test_out/\", \n",
    "#                     force=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4f6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def extract_figures_from_tei(tei_file_path):\n",
    "    \"\"\"\n",
    "    Extract figures from TEI XML and return structured data\n",
    "    \n",
    "    Args:\n",
    "        tei_file_path (str): Path to the TEI XML file\n",
    "        \n",
    "    Returns:\n",
    "        list: Extracted figures data\n",
    "    \"\"\"\n",
    "    with open(tei_file_path, 'r', encoding='utf-8') as tei:\n",
    "        soup = BeautifulSoup(tei, 'lxml-xml')\n",
    "    \n",
    "    figures = soup.find_all('figure')\n",
    "    result = []\n",
    "    \n",
    "    # Track the order of figures in the XML\n",
    "    order_index = 0\n",
    "    \n",
    "    for figure in figures:\n",
    "        figure_obj = {}\n",
    "        \n",
    "        # Add order index to track position in the original XML\n",
    "        figure_obj['order_index'] = order_index\n",
    "        order_index += 1\n",
    "        \n",
    "        # Extract figure ID if available\n",
    "        figure_id = figure.get('xml:id')\n",
    "        if figure_id:\n",
    "            figure_obj['figure_id'] = figure_id\n",
    "        \n",
    "        # Extract the heading/caption\n",
    "        head = figure.find('head')\n",
    "        if head:\n",
    "            head_text = head.get_text()\n",
    "            clean_head_text = ' '.join(head_text.split())\n",
    "            figure_obj['head'] = clean_head_text\n",
    "            \n",
    "            # Get label if available\n",
    "            label = figure.find('label')\n",
    "            if label:\n",
    "                figure_obj['label'] = label.get_text().strip()\n",
    "        \n",
    "        # # Extract figure description\n",
    "        # fig_desc = figure.find('figDesc')\n",
    "        # if fig_desc:\n",
    "        #     desc_text = fig_desc.get_text()\n",
    "        #     clean_desc_text = ' '.join(desc_text.split())\n",
    "        #     figure_obj['description'] = clean_desc_text\n",
    "        \n",
    "        # # Extract graphic information if available\n",
    "        # graphic = figure.find('graphic')\n",
    "        # if graphic:\n",
    "        #     figure_obj['graphic'] = {\n",
    "        #         'url': graphic.get('url', ''),\n",
    "        #         'coords': graphic.get('coords', ''),\n",
    "        #         'type': graphic.get('type', '')\n",
    "        #     }\n",
    "        \n",
    "        result.append(figure_obj)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c99761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 figures\n",
      "\n",
      "First 5 figures:\n",
      "[   {   'figure_id': 'fig_0',\n",
      "        'head': 'Table A. 1 :',\n",
      "        'label': '1',\n",
      "        'order_index': 0},\n",
      "    {'figure_id': 'fig_1', 'order_index': 1},\n",
      "    {   'figure_id': 'fig_2',\n",
      "        'head': 'Figure 1 :',\n",
      "        'label': '1',\n",
      "        'order_index': 2},\n",
      "    {'figure_id': 'fig_3', 'order_index': 3},\n",
      "    {   'figure_id': 'fig_4',\n",
      "        'head': 'Figure 3 :',\n",
      "        'label': '3',\n",
      "        'order_index': 4},\n",
      "    {'figure_id': 'fig_6', 'order_index': 5},\n",
      "    {   'figure_id': 'fig_7',\n",
      "        'head': 'Figure A. 1 :',\n",
      "        'label': '1',\n",
      "        'order_index': 6},\n",
      "    {   'figure_id': 'fig_8',\n",
      "        'head': 'Figure A. 2 :',\n",
      "        'label': '2',\n",
      "        'order_index': 7},\n",
      "    {   'figure_id': 'fig_9',\n",
      "        'head': 'Figure A. 3 :',\n",
      "        'label': '3',\n",
      "        'order_index': 8},\n",
      "    {'figure_id': 'fig_10', 'head': 'Figure', 'order_index': 9},\n",
      "    {'order_index': 10},\n",
      "    {'order_index': 11},\n",
      "    {'order_index': 12},\n",
      "    {'order_index': 13},\n",
      "    {'order_index': 14},\n",
      "    {'order_index': 15},\n",
      "    {'order_index': 16},\n",
      "    {'order_index': 17},\n",
      "    {'order_index': 18},\n",
      "    {'order_index': 19},\n",
      "    {'order_index': 20},\n",
      "    {'order_index': 21},\n",
      "    {'order_index': 22},\n",
      "    {'order_index': 23},\n",
      "    {'order_index': 24},\n",
      "    {'order_index': 25},\n",
      "    {'order_index': 26},\n",
      "    {'order_index': 27},\n",
      "    {'order_index': 28},\n",
      "    {'order_index': 29},\n",
      "    {'order_index': 30},\n",
      "    {'order_index': 31},\n",
      "    {'order_index': 32},\n",
      "    {'order_index': 33},\n",
      "    {'order_index': 34},\n",
      "    {'order_index': 35},\n",
      "    {'order_index': 36},\n",
      "    {'order_index': 37},\n",
      "    {'order_index': 38},\n",
      "    {'order_index': 39},\n",
      "    {'order_index': 40},\n",
      "    {'order_index': 41},\n",
      "    {'order_index': 42}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Example usage in notebook:\n",
    "tei_path = \"./test.grobid.tei.xml\"\n",
    "figures = extract_figures_from_tei(tei_path)\n",
    "print(f\"Found {len(figures)} figures\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "print(\"\\nFirst 5 figures:\")\n",
    "pp.pprint(figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d9a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 78 images from the PDF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "pdf_document = fitz.open(\"./test.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "# Create directory for extracted images if it doesn't exist\n",
    "output_dir = Path(\"extracted_images\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process all pages in the PDF\n",
    "extracted_image_paths = []\n",
    "\n",
    "for page_num in range(len(pdf_document)):\n",
    "    # Get the page\n",
    "    page = pdf_document[page_num]\n",
    "    \n",
    "    # Extract images from the page\n",
    "    image_list = page.get_images(full=True)\n",
    "    \n",
    "    # Process each image on the page\n",
    "    for img_index, img in enumerate(image_list):\n",
    "        try:\n",
    "            xref = img[0]  # image reference\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            \n",
    "            # Convert extension to standard format if needed\n",
    "            if image_ext.lower() == \"jpeg\":\n",
    "                file_ext = \"jpeg\"\n",
    "            else:\n",
    "                file_ext = image_ext.lower()\n",
    "            \n",
    "            # Create a filename for the image\n",
    "            image_filename = f\"page{page_num+1}_img{img_index+1}.{file_ext}\"\n",
    "            image_path = output_dir / image_filename\n",
    "            \n",
    "            # Save the image\n",
    "            with open(image_path, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "                \n",
    "            # Add to the list of extracted paths\n",
    "            extracted_image_paths.append(str(image_path))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting image {img_index} from page {page_num+1}: {e}\")\n",
    "\n",
    "print(f\"Extracted {len(extracted_image_paths)} images from the PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5e6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed data to 'parsed_document.csv' with 228 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pdf_url = \"https://arxiv.org/pdf/2106.00676.pdf\" # link/to/your/paper.pdf \n",
    "relative_coordinates = True # whether returning relative coordinates or not \n",
    "# Read the data from the API\n",
    "parsed = pd.read_csv(f\"http://34.131.181.227:8080/parse/?pdf_url={pdf_url}&relative_coordinates={relative_coordinates}\")\n",
    "\n",
    "# Save the parsed data to a CSV file\n",
    "parsed.to_csv('parsed_document.csv', index=False)\n",
    "print(f\"Saved parsed data to 'parsed_document.csv' with {len(parsed)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d657ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import layoutparser as lp\n",
    "# page_tokens, page_images = lp.load_pdf(\"test.pdf\", load_images=True)\n",
    "# for page_id in range(len(page_images)):\n",
    "#     cur_page_w, cur_page_h = page_images[page_id].size\n",
    "#     tdf = (parsed[parsed['page']==page_id][[\"x1\", \"y1\", \"x2\", \"y2\"]])\n",
    "#     tdf['x1'] *= cur_page_w\n",
    "#     tdf['x2'] *= cur_page_w\n",
    "#     tdf['y1'] *= cur_page_h\n",
    "#     tdf['y2'] *= cur_page_h\n",
    "#     tdf = tdf.rename(columns={\"x1\":\"x_1\", \"y1\":\"y_1\", \"x2\":\"x_2\", \"y2\":\"y_2\"})\n",
    "#     display(\n",
    "#         lp.draw_box(\n",
    "#         page_images[page_id],\n",
    "#         lp.load_dataframe(tdf,block_type=\"rectangle\")\n",
    "#         )\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c5ad98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     page       type                                               text  \\\n",
      "0       0      Title  VILA: Improving Structured Content Extraction ...   \n",
      "1       0     Author  Zejiang Shen 1 Kyle Lo 1 Lucy Lu Wang 1 Bailey...   \n",
      "2       0   Abstract  Abstract Accurately extracting structured cont...   \n",
      "3       0    Section                                     1 Introduction   \n",
      "4       0  Paragraph  Scientiﬁc papers are usually distributed in Po...   \n",
      "..    ...        ...                                                ...   \n",
      "223    16    Caption  Table 9: Prediction F1 breakdown for all model...   \n",
      "224    16    Section                               Correct Label Errors   \n",
      "225    16  Paragraph  Given the VILA struc- tures, we can easily cor...   \n",
      "226    16  Paragraph  “paragraph”.Weupdate our methods for several r...   \n",
      "227    16   Footnote  15 We randomly sample 30 pages from both the t...   \n",
      "\n",
      "           x1        y1        x2        y2 block_type  block_id  \n",
      "0    0.138936  0.083545  0.862794  0.119515        NaN       NaN  \n",
      "1    0.179837  0.139729  0.827769  0.207312        NaN       NaN  \n",
      "2    0.156409  0.244707  0.455433  0.704318        NaN       NaN  \n",
      "3    0.120805  0.738514  0.259754  0.752712        NaN       NaN  \n",
      "4    0.120805  0.767244  0.490074  0.908934        NaN       NaN  \n",
      "..        ...       ...       ...       ...        ...       ...  \n",
      "223  0.120287  0.435350  0.881781  0.461381      Table       3.0  \n",
      "224  0.120805  0.487818  0.294015  0.500774        NaN       NaN  \n",
      "225  0.120805  0.487909  0.490283  0.661782        NaN       NaN  \n",
      "226  0.118371  0.664917  0.490067  0.774423        NaN       NaN  \n",
      "227  0.120099  0.817953  0.489657  0.908436        NaN       NaN  \n",
      "\n",
      "[228 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec46355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io\n",
    "f = open(\"test.pdf\", 'rb')\n",
    "files = {\"pdf_file\": (f.name, f, \"multipart/form-data\")}\n",
    "r = requests.post('http://34.131.181.227:8080/parse', files=files)\n",
    "parsed = pd.read_csv(io.StringIO(r.content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa61375",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed.to_csv('parsed_document2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_grobid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
